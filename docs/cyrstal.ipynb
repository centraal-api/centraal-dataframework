{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pysftp==0.2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports generales\n",
    "import pysftp\n",
    "import logging\n",
    "import sys\n",
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar directorio CDF y Configuraciones\n",
    "sys.path.append('../')\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Importar CDF\n",
    "from centraal_dataframework.resources import datalake\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "from centraal_dataframework.tasks import task_dq, task\n",
    "\n",
    "# Preparación de ambiente\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traer Archivos SFTP\n",
    "@task\n",
    "def get_scrapping_file(datalake, logger):\n",
    "    # Variables\n",
    "    last_file_date = 0\n",
    "    last_file_name = ''\n",
    "    scrapping_file = None\n",
    "    csv_output_dir = os.environ['datalake_workdir'] + '/' + os.environ['scrapping_workdir'] + '/'\n",
    "    # Abrir conexión\n",
    "    cnopts = pysftp.CnOpts()\n",
    "    cnopts.hostkeys = None\n",
    "    sftp = pysftp.Connection(\n",
    "        host=os.environ['sftp_servidor'],\n",
    "        port=int(os.environ['sftp_port']),\n",
    "        username=os.environ['sftp_usuario'],\n",
    "        password=os.environ['sftp_clave'],\n",
    "        cnopts=cnopts,\n",
    "    )\n",
    "    sftp.cwd(os.environ['sftp_raiz'])\n",
    "    # Buscar el último archivo\n",
    "    archivos = sftp.listdir_attr()\n",
    "    for archivo in archivos:\n",
    "        if archivo.longname[0] != 'd':\n",
    "            if archivo.st_atime > last_file_date:\n",
    "                last_file_date = archivo.st_atime\n",
    "                last_file_name = archivo.filename\n",
    "    # Cargar el archivo al DataFrame\n",
    "    with sftp.open(last_file_name) as sfile:\n",
    "        scrapping_file = pd.read_csv(sfile, sep=',', encoding='latin1')\n",
    "    sftp.close()\n",
    "    # Escribimos el DataFrame en nuestro raw-zone\n",
    "    datalake.write_csv(scrapping_file, csv_output_dir + 'scrapping.csv', sep='|', index=False, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task_dq\n",
    "def scrapping_validate_prerequisites(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Valida los pre-requisitos básicos del archivo de Scrapping\"\"\"\n",
    "    csv_input_dir = os.environ['datalake_workdir'] + '/' + os.environ['scrapping_workdir'] + '/'\n",
    "    source = datalake.read_csv(csv_input_dir + \"scrapping.csv\", sep=\"|\", encoding = 'latin1')\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando prerrequisitos del archivo Scrapping...\")\n",
    "\n",
    "    #Nombres de columnas\n",
    "    scrapping_column_names = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_table_columns_to_match_set\",\n",
    "        kwargs={\n",
    "            \"column_set\":    [\"date\", \"canal\", \"category\", \"subcategory\", \"subcategory2\",\n",
    "                            \"subcategory3\", \"marca\", \"modelo\", \"sku\", \"upc\", \"item\",\n",
    "                            \"item characteristics\", \"url sku\", \"image\", \"price\", \"sale price\",\n",
    "                            \"shipment cost\", \"sales flag\", \"store id\", \"store name\",\n",
    "                            \"store address\", \"stock\", \"upc wm\", \"final price\", \"upc wm2\", \"comp\",\n",
    "                            \"composition\", \"homogenized_clothing\", \"homogenized_subcategory\",\n",
    "                            \"homogenized_category\", \"homogenized_color\", \"made_in\"\n",
    "                            ],\n",
    "            \"exact_match\":   True,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Las columnas del archivo de Scrapping no concuerdan con las esperadas\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    #Price Not Null\n",
    "    scrapping_price_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\n",
    "            \"column\":        \"price\",\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos precios del archivo de Scrapping no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    #ADD EXPECTATIONS\n",
    "    url = gx_toolkit.run_expectations_on_df(source, \"SCRAPPING_MANDATORY\", [scrapping_column_names, scrapping_price_notnull])\n",
    "    print(\"reporte de expectativas\", url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TAREA: scrapping_validate_prerequisites--2023-11-29 07:37:27,472-INFO-         date          canal category subcategory   subcategory2 subcategory3  \\\n",
      "0  05/10/2023  Zara Colombia   Hombre      JERSEY  F. Jersey M/C          NaN   \n",
      "\n",
      "  marca   modelo        sku                   upc  ...     upc wm final price  \\\n",
      "0  Zara  MarrÃ³n  275572806  275572806_MarrÃ³n_XL  ...  275572806    249000.0   \n",
      "\n",
      "     upc wm2 comp                                        composition  \\\n",
      "0  275572806  NaN  Exterior: 100% poliÃ©ster: que contiene al men...   \n",
      "\n",
      "   homogenized_clothing homogenized_subcategory homogenized_category  \\\n",
      "0             Chaquetas           Ropa exterior               Hombre   \n",
      "\n",
      "  homogenized_color made_in  \n",
      "0             CafÃ©   China  \n",
      "\n",
      "[1 rows x 32 columns]\n",
      "TAREA: scrapping_validate_prerequisites--2023-11-29 07:37:27,480-INFO-Validando prerrequisitos del archivo Scrapping...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2124a470d84ebebfe76dc01b3d6b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reporte de expectativas Se genera un archivo privado: /calidad-datos/validations/scrapping_validate_prerequisites_expectation_suite/__none__/20231129T123727.787594Z/scrapping_validate_prerequisites_source-scrapping_validate_prerequisites_source_SCRAPPING_MANDATORY.html. Visitar portal azure para acceder resultados.\n"
     ]
    }
   ],
   "source": [
    "scrapping_validate_prerequisites()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task_dq\n",
    "def scrapping_validate_column_contents(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Identifica inconsistencias en el contenido de las columnas del archivo Scrapping\"\"\"\n",
    "    csv_input_dir = os.environ['datalake_workdir'] + '/' + os.environ['scrapping_workdir'] + '/'\n",
    "    source = datalake.read_csv(csv_input_dir+\"scrapping.csv\", sep=\"|\", encoding = 'latin1')\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando contenido de columnas del archivo Scrapping...\")\n",
    "    # creaciones de expectativas\n",
    "\n",
    "    scrapping_clothing_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\n",
    "            \"column\":        \"clothing\",\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'clothing' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    #homogenized_category NOT NULL\n",
    "    scrapping_homogenized_category_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\n",
    "            \"column\":        \"homogenized_category\",\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'homogenized_category' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    #homogenized_subcategory NOT NULL\n",
    "    scrapping_homogenized_subcategory_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\n",
    "            \"column\":        \"homogenized_subcategory\",\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'homogenized_subcategory' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    #homogenized_color NOT NULL\n",
    "    scrapping_homogenized_color_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\n",
    "            \"column\":        \"homogenized_color\",\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'homogenized_color' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    #marca 9 values (up to 11) <- PARAMETER\n",
    "    scrapping_marca_unique = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_unique_value_count_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":        \"marca\",\n",
    "            \"min_value\":     9,\n",
    "            \"max_value\":     11,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'homogenized_color' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    url = gx_toolkit.run_expectations_on_df(source, \"SCRAPPING_CONSISTENCE\", [scrapping_clothing_notnull, scrapping_homogenized_category_notnull,\n",
    "                                                                              scrapping_homogenized_subcategory_notnull, scrapping_homogenized_color_notnull,\n",
    "                                                                              scrapping_marca_unique])\n",
    "    print(\"reporte de expectativas\", url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapping_validate_column_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task_dq\n",
    "def scrapping_validate_prices(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Valida el rango de precios del archivo de Scrapping\n",
    "       Según el lote Zara y de las demás marcas\"\"\"\n",
    "    csv_input_dir = os.environ['datalake_workdir'] + '/' + os.environ['scrapping_workdir'] + '/'\n",
    "    source = datalake.read_csv(csv_input_dir + \"scrapping.csv\", sep=\"|\", encoding = 'latin1')\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando contenido de columnas del archivo Scrapping...\")\n",
    "    # creaciones de expectativas\n",
    "    #Final Price\n",
    "    #Precio Final Between\n",
    "    ##Zara 12.000 - 4.000.000\n",
    "    scrapping_zara_price_range = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":        \"final price\",\n",
    "            \"min_value\":     12000,\n",
    "            \"max_value\":     4000000,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Para la marca Zara, algunos precios no se encuentran en el rango esperado.\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    ##Otras - 12.000 - 1.300.000\n",
    "    scrapping_otras_price_range = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":        \"final price\",\n",
    "            \"min_value\":     12000,\n",
    "            \"max_value\":     1300000,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos precios no se encuentran en el rango esperado.\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    url = gx_toolkit.run_expectations_on_df(source[source['canal'] == 'Zara Colombia'], \"SCRAPPING_PRECIOS_ZARA\", [scrapping_zara_price_range])\n",
    "    print(\"reporte de expectativas\", url)\n",
    "    url = gx_toolkit.run_expectations_on_df(source[source['canal'] != 'Zara Colombia'], \"SCRAPPING_PRECIOS\", [scrapping_otras_price_range])\n",
    "    print(\"reporte de expectativas\", url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapping_validate_prices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task_dq\n",
    "def marcaspropias_validate_column_contents(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Validar el contenido de las columnas de marcas propias\"\"\"\n",
    "    csv_input_dir = os.environ['datalake_workdir'] + '/' + os.environ['datasvcs_workdir'] + '/'\n",
    "    source = datalake.read_csv(csv_input_dir + \"marcas_propias.csv\", sep=\",\")\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando contenido de columnas del archivo Marcas Propias...\")\n",
    "    # creaciones de expectativas\n",
    "    marcprop_categoria_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\n",
    "            \"column\":        \"categoria\",\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'categoria' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    #Uso NOT NULL\n",
    "    marcprop_use_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\n",
    "            \"column\":        \"use\",\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'use' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    #Tipo Prenda NOT NULL\n",
    "    marcprop_tipo_prenda_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\n",
    "            \"column\":        \"prendasGenerales\", #??????\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'prendasGenerales' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    url = gx_toolkit.run_expectations_on_df(source, \"MARCAS_PROPIAS_CONSISTENCY\", [marcprop_categoria_notnull, marcprop_use_notnull,\n",
    "                                                                                   marcprop_tipo_prenda_notnull])\n",
    "    print(\"reporte de expectativas\", url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marcaspropias_validate_column_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task_dq\n",
    "def homologaciones_validar_cantidad(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Valida la cantidad de marcas que existen en el archivo de homologaciones\"\"\"\n",
    "    csv_input_dir = os.environ['datalake_workdir'] + '/' + os.environ['homologa_workdir'] + '/'\n",
    "    source = datalake.read_csv(csv_input_dir + \"homologaciones.csv\", sep=\",\")\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando cantidad de registros en homologaciones..\")\n",
    "    homologacion_marca_join = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_unique_value_count_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":        \"Marca\",\n",
    "            \"min_value\":     9,\n",
    "            \"max_value\":     11,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'marca' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    url = gx_toolkit.run_expectations_on_df(source, \"CANTIDAD_MARCAS_HOMOLOGACION\", [homologacion_marca_join])\n",
    "    print(\"reporte de expectativas\", url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homologaciones_validar_cantidad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task_dq\n",
    "def ordentallas_validar_join(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Validación de Orden Tallas para Join\"\"\"\n",
    "    csv_input_dir = os.environ['datalake_workdir'] + '/' + os.environ['homologa_workdir'] + '/'\n",
    "    source = datalake.read_csv(csv_input_dir + \"orden_tallas.csv\", sep=\",\")\n",
    "    validation_set = datalake.read_csv(csv_input_dir + \"homologaciones.csv\", sep=\",\")\n",
    "    marcas_set = validation_set.Marca.unique().tolist()\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando JOIN Orden Tallas...\")\n",
    "\n",
    "    ordentallas_marca_join = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_in_set\",\n",
    "        kwargs={\n",
    "            \"column\":        \"Marca\",\n",
    "            \"value_set\":      marcas_set,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'marca' no están presentes en el archivo de Orden Tallas\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    url = gx_toolkit.run_expectations_on_df(source, \"ORDENTALLA_MARCAS_JOIN\", [ordentallas_marca_join])\n",
    "    print(\"reporte de expectativas\", url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordentallas_validar_join()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ean_validar_cantidad_registros(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Valida la canitdad de EANs\"\"\"\n",
    "    csv_input_dir = os.environ['datalake_workdir'] + '/' + os.environ['homologa_workdir'] + '/'\n",
    "    source = datalake.read_csv(csv_input_dir + \"ean.csv\", sep=\"|\")\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando Cantidad EAN...\")\n",
    "    ean_unique = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_unique_value_count_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":        \"EAN\",\n",
    "            \"min_value\":     3000,\n",
    "            \"max_value\":     4000,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"La cantidad de productos presentes excede la esperada\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    url = gx_toolkit.run_expectations_on_df(source, \"CANTIDAD_EAN\", [ean_unique])\n",
    "    print(\"reporte de expectativas\", url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ean = datalake.read_csv('raw-zone/blackBox/scrapingEquivalencias/EAN_COMPLEMENTOS.csv')\n",
    "ean\n",
    "#ean = pd.read_csv('C:\\\\Users\\\\Wilber\\\\Download\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task_dq\n",
    "def tallasagotadas_validar_join(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Veriifca los EAN para el cruce\"\"\"\n",
    "    csv_input_dir = os.environ['datalake_workdir'] + '/' + os.environ['homologa_workdir'] + '/'\n",
    "    source = datalake.read_csv(\"cleansed-zone/tallas_agotadas.csv\", sep=\"|\")\n",
    "    validation_set = datalake.read_csv(\"cleansed-zone/ean.csv\", sep=\"|\")\n",
    "    marcas_set = validation_set.EAN.unique()\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando JOIN Orden Tallas...\")\n",
    "\n",
    "    tallasagotadas_marca_join = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_in_set\",\n",
    "        kwargs={\n",
    "            \"column\":        \"Marca\",\n",
    "            \"valueset\":      marcas_set,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'marca' no están presentes en el archivo de Orden Tallas\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    url = gx_toolkit.run_expectations_on_df(source, \"test\", [tallasagotadas_marca_join])\n",
    "    print(\"reporte de expectativas\", url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
