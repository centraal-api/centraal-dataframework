{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pysftp==0.2.9\n",
    "#Imports presentacion\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports generales\n",
    "import pysftp\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar directorio CDF y Configuraciones\n",
    "sys.path.append('../')\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Importar CDF\n",
    "from centraal_dataframework.resources import datalake\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "from centraal_dataframework.tasks import task_dq, task\n",
    "from centraal_dataframework.excepciones import ErrorTareaCalidadDatos\n",
    "from centraal_dataframework.resources import GreatExpectationsToolKit\n",
    "from centraal_dataframework.runner import Runner\n",
    "\n",
    "# Preparación de ambiente\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENEDOR_DESTINO = os.environ.get('datalake_cleandir', 'cleansed-zone')\n",
    "WD = os.environ.get('datalake_workdir', 'raw-zone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# registro de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tarea get_scrapping_file sobrescrita. Si quiere cambiar este comportamiento\n",
      "use la variable de ambiente `SOBREESCRIBIR_TAREA` (valor actual = True)\n"
     ]
    }
   ],
   "source": [
    "# Traer Archivos SFTP\n",
    "@task\n",
    "def get_scrapping_file(datalake, logger):\n",
    "    # Variables\n",
    "    last_file_date = 0\n",
    "    last_file_name = ''\n",
    "    scrapping_file = None\n",
    "    \n",
    "    # Abrir conexión\n",
    "    cnopts = pysftp.CnOpts()\n",
    "    cnopts.hostkeys = None\n",
    "    sftp = pysftp.Connection(\n",
    "        host=os.environ['sftp_servidor'],\n",
    "        port=int(os.environ['sftp_port']),\n",
    "        username=os.environ['sftp_usuario'],\n",
    "        password=os.environ['sftp_clave'],\n",
    "        cnopts=cnopts,\n",
    "    )\n",
    "    sftp.cwd(os.environ['sftp_raiz'])\n",
    "    # Buscar el último archivo\n",
    "    archivos = sftp.listdir_attr()\n",
    "    for archivo in archivos:\n",
    "        if archivo.longname[0] != 'd':\n",
    "            if archivo.st_atime > last_file_date:\n",
    "                last_file_date = archivo.st_atime\n",
    "                last_file_name = archivo.filename\n",
    "    # Cargar el archivo al DataFrame\n",
    "    with sftp.open(last_file_name) as sfile:\n",
    "        scrapping_file = pd.read_csv(sfile, sep=',', encoding='latin1')\n",
    "        sftp.close()\n",
    "    # Escribimos el DataFrame en nuestro raw-zone\n",
    "    csv_output_dir = f\"{CONTENEDOR}/{WD}\"\n",
    "    datalake.write_csv(scrapping_file, f\"{csv_output_dir}/scrapping.csv\", sep='|', index=False, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tarea scrapping_validate_prerequisites sobrescrita. Si quiere cambiar este comportamiento\n",
      "use la variable de ambiente `SOBREESCRIBIR_TAREA` (valor actual = True)\n"
     ]
    }
   ],
   "source": [
    "@task_dq\n",
    "def scrapping_validate_prerequisites(datalake, gx_toolkit: GreatExpectationsToolKit, logger):\n",
    "    \"\"\"Valida los pre-requisitos básicos del archivo de Scrapping\"\"\"\n",
    "    csv_input_dir = WD + '/scrapping/'\n",
    "    source = datalake.read_csv(csv_input_dir + \"scrapping.csv\", sep=\"|\", encoding='latin1')\n",
    "    logger.info(\"Validando prerrequisitos del archivo Scrapping...\")\n",
    "\n",
    "    # Nombres de columnas\n",
    "    scrapping_column_names = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_table_columns_to_match_set\",\n",
    "        kwargs={\n",
    "            \"column_set\": [\n",
    "                \"date\",\n",
    "                \"canal\",\n",
    "                \"category\",\n",
    "                \"subcategory\",\n",
    "                \"subcategory2\",\n",
    "                \"subcategory3\",\n",
    "                \"marca\",\n",
    "                \"modelo\",\n",
    "                \"sku\",\n",
    "                \"upc\",\n",
    "                \"item\",\n",
    "                \"item characteristics\",\n",
    "                \"url sku\",\n",
    "                \"image\",\n",
    "                \"price\",\n",
    "                \"sale price\",\n",
    "                \"shipment cost\",\n",
    "                \"sales flag\",\n",
    "                \"store id\",\n",
    "                \"store name\",\n",
    "                \"store address\",\n",
    "                \"stock\",\n",
    "                \"upc wm\",\n",
    "                \"final price\",\n",
    "                \"upc wm2\",\n",
    "                \"comp\",\n",
    "                \"composition\",\n",
    "                \"homogenized_clothing\",\n",
    "                \"homogenized_subcategory\",\n",
    "                \"homogenized_category\",\n",
    "                \"homogenized_color\",\n",
    "                \"made_in\",\n",
    "            ],\n",
    "            \"exact_match\": True,\n",
    "            \"result_format\": \"SUMMARY\",\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Las columnas del archivo de Scrapping no concuerdan con las esperadas\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Price Not Null\n",
    "    scrapping_price_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"price\", \"result_format\": \"SUMMARY\"},\n",
    "        meta={\n",
    "            \"notes\": {\"format\": \"markdown\", \"content\": \"Algunos precios del archivo de Scrapping no están presentes\"}\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # EXECUTE EXPECTATIONS\n",
    "    url, result = gx_toolkit.run_expectations_on_df(\n",
    "        source, \"SCRAPPING_MANDATORY\", [scrapping_column_names, scrapping_price_notnull]\n",
    "    )\n",
    "    clear_output(wait=True)\n",
    "    if result.success:\n",
    "        logger.info('Validación exitosa, se promueve a cleansed-zone')\n",
    "        logger.info(url)\n",
    "        csv_output_dir = f\"{CONTENEDOR_DESTINO}/{WD}/scrapping.csv\"\n",
    "        datalake.write_csv(source, csv_output_dir, sep=\"|\", encoding='latin1')\n",
    "    else:\n",
    "        logger.info('ERROR: Validación fallida, se detiene el proceso.')\n",
    "        logger.info(url)\n",
    "        raise ErrorTareaCalidadDatos(result, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tarea scrapping_validate_column_contents sobrescrita. Si quiere cambiar este comportamiento\n",
      "use la variable de ambiente `SOBREESCRIBIR_TAREA` (valor actual = True)\n"
     ]
    }
   ],
   "source": [
    "@task_dq\n",
    "def scrapping_validate_column_contents(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Identifica inconsistencias en el contenido de las columnas del archivo Scrapping\"\"\"\n",
    "    csv_input_dir = f'{WD}/scrapping/'\n",
    "    source = datalake.read_csv(csv_input_dir+\"scrapping.csv\", sep=\"|\", encoding = 'latin1')\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando contenido de columnas del archivo Scrapping...\")\n",
    "    # creaciones de expectativas\n",
    "\n",
    "    scrapping_clothing_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\n",
    "            \"column\":        \"clothing\",\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'clothing' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    #homogenized_category NOT NULL\n",
    "    scrapping_homogenized_category_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\n",
    "            \"column\":        \"homogenized_category\",\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'homogenized_category' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    #homogenized_subcategory NOT NULL\n",
    "    scrapping_homogenized_subcategory_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\n",
    "            \"column\":        \"homogenized_subcategory\",\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'homogenized_subcategory' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    #homogenized_color NOT NULL\n",
    "    scrapping_homogenized_color_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\n",
    "            \"column\":        \"homogenized_color\",\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'homogenized_color' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    #marca 9 values (up to 11) <- PARAMETER\n",
    "    scrapping_marca_unique = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_unique_value_count_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":        \"marca\",\n",
    "            \"min_value\":     9,\n",
    "            \"max_value\":     11,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'homogenized_color' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    result = gx_toolkit.run_expectations_on_df(source, \"SCRAPPING_CONSISTENCE\", [scrapping_clothing_notnull, scrapping_homogenized_category_notnull,\n",
    "                                                                              scrapping_homogenized_subcategory_notnull, scrapping_homogenized_color_notnull,\n",
    "                                                                              scrapping_marca_unique])\n",
    "    clear_output(wait=True)\n",
    "    if result['status']:\n",
    "        logger.info('Validación exitosa, se promueve a cleansed-zone')\n",
    "    else:\n",
    "        logger.info('WARNING: Validación fallida, continúa.')\n",
    "        logger.info(url)\n",
    "    csv_output_dir = CONTENEDOR_DESTINO + '/scrapping/'\n",
    "    datalake.write_csv(source, csv_output_dir+'scrapping.csv', sep=\"|\", encoding = 'latin1')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tarea scrapping_validate_prices sobrescrita. Si quiere cambiar este comportamiento\n",
      "use la variable de ambiente `SOBREESCRIBIR_TAREA` (valor actual = True)\n"
     ]
    }
   ],
   "source": [
    "@task_dq\n",
    "def scrapping_validate_prices(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Valida el rango de precios del archivo de Scrapping\n",
    "       Según el lote Zara y de las demás marcas\"\"\"\n",
    "    csv_input_dir = WD + '/scrapping/'\n",
    "    source = datalake.read_csv(csv_input_dir + \"scrapping.csv\", sep=\"|\", encoding = 'latin1')\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando contenido de columnas del archivo Scrapping...\")\n",
    "    # creaciones de expectativas\n",
    "    #Final Price\n",
    "    #Precio Final Between\n",
    "    ##Zara 12.000 - 4.000.000\n",
    "    scrapping_zara_price_range = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":        \"final price\",\n",
    "            \"min_value\":     12000,\n",
    "            \"max_value\":     4000000,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Para la marca Zara, algunos precios no se encuentran en el rango esperado.\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    ##Otras - 12.000 - 1.300.000\n",
    "    scrapping_otras_price_range = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":        \"final price\",\n",
    "            \"min_value\":     12000,\n",
    "            \"max_value\":     1300000,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos precios no se encuentran en el rango esperado.\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    result_zara  = gx_toolkit.run_expectations_on_df(source[source['canal'] == 'Zara Colombia'], \"SCRAPPING_PRECIOS_ZARA\", [scrapping_zara_price_range])\n",
    "    result_otras = gx_toolkit.run_expectations_on_df(source[source['canal'] != 'Zara Colombia'], \"SCRAPPING_PRECIOS\", [scrapping_otras_price_range])\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    if result_zara['status'] and result_otras['status']:\n",
    "        logger.info('Validación exitosa, se promueve a cleansed-zone')\n",
    "    else:\n",
    "        logger.info('WARNING: Validación fallida, continúa.')\n",
    "        logger.info('ZARA:  '+result_zara['url'])\n",
    "        logger.info('OTRAS: '+result_otras['url'])\n",
    "    csv_output_dir = CONTENEDOR_DESTINO + '/scrapping/'\n",
    "    datalake.write_csv(source, csv_output_dir+'scrapping.csv', sep=\"|\", encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tarea marcaspropias_validate_column_contents sobrescrita. Si quiere cambiar este comportamiento\n",
      "use la variable de ambiente `SOBREESCRIBIR_TAREA` (valor actual = True)\n"
     ]
    }
   ],
   "source": [
    "@task_dq\n",
    "def marcaspropias_validate_column_contents(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Validar el contenido de las columnas de marcas propias\"\"\"\n",
    "    csv_input_dir = WD + '/' + dataservices + '/'\n",
    "    source = datalake.read_csv(csv_input_dir + \"marcas_propias.csv\", sep=\",\", encoding='utf8')\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando contenido de columnas del archivo Marcas Propias...\")\n",
    "    # creaciones de expectativas\n",
    "    marcprop_categoria_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\n",
    "            \"column\":        \"categoria\",\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'categoria' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    #Uso NOT NULL\n",
    "    marcprop_use_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\n",
    "            \"column\":        \"use\",\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'use' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    #Tipo Prenda NOT NULL\n",
    "    marcprop_tipo_prenda_notnull = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\n",
    "            \"column\":        \"prendasGenerales\", #??????\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'prendasGenerales' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    result = gx_toolkit.run_expectations_on_df(source, \"MARCAS_PROPIAS_CONSISTENCY\", [marcprop_categoria_notnull, marcprop_use_notnull,\n",
    "                                                                                   marcprop_tipo_prenda_notnull])\n",
    "    clear_output(wait=True)\n",
    "    if result['status']:\n",
    "        logger.info('Validación exitosa, se promueve a cleansed-zone')\n",
    "    else:\n",
    "        logger.info('WARNING: Validación fallida, continúa.')\n",
    "        logger.info(url)\n",
    "    csv_output_dir = CONTENEDOR_DESTINO + '/' + dataservices + '/'\n",
    "    datalake.write_csv(source, csv_output_dir+'marcas_propias.csv', sep=\"|\", encoding='utf8')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tarea homologaciones_validar_cantidad sobrescrita. Si quiere cambiar este comportamiento\n",
      "use la variable de ambiente `SOBREESCRIBIR_TAREA` (valor actual = True)\n"
     ]
    }
   ],
   "source": [
    "@task_dq\n",
    "def homologaciones_validar_cantidad(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Valida la cantidad de marcas que existen en el archivo de homologaciones\"\"\"\n",
    "    csv_input_dir = WD + '/' + homologaciones + '/'\n",
    "    source = datalake.read_csv(csv_input_dir + \"homologaciones.csv\", sep=\",\")\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando cantidad de registros en homologaciones..\")\n",
    "    homologacion_marca_join = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_unique_value_count_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":        \"Marca\",\n",
    "            \"min_value\":     9,\n",
    "            \"max_value\":     11,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'marca' no están presentes\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    result = gx_toolkit.run_expectations_on_df(source, \"CANTIDAD_MARCAS_HOMOLOGACION\", [homologacion_marca_join])\n",
    "    clear_output(wait=True)\n",
    "    if result['status']:\n",
    "        logger.info('Validación exitosa, se promueve a cleansed-zone')\n",
    "    else:\n",
    "        logger.info('WARNING: Validación fallida, continúa.')\n",
    "        logger.info(url)\n",
    "    csv_output_dir = CONTENEDOR_DESTINO + '/' + homologaciones + '/'\n",
    "    datalake.write_csv(source, csv_output_dir+'homologaciones.csv', sep=\"|\", encoding='utf8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tarea ordentallas_validar_join sobrescrita. Si quiere cambiar este comportamiento\n",
      "use la variable de ambiente `SOBREESCRIBIR_TAREA` (valor actual = True)\n"
     ]
    }
   ],
   "source": [
    "@task_dq\n",
    "def ordentallas_validar_join(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Validación de Orden Tallas para Join\"\"\"\n",
    "    csv_input_dir = WD + '/' + homologaciones + '/'\n",
    "    source = datalake.read_csv(csv_input_dir + \"orden_tallas.csv\", sep=\",\")\n",
    "    csv_input_dir = WD + '/scrapping/'\n",
    "    validation_set = datalake.read_csv(csv_input_dir + \"scrapping.csv\", sep=\"|\", encoding='latin1')\n",
    "    tallas_set = validation_set.stock.unique().tolist()\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando JOIN Orden Tallas...\")\n",
    "\n",
    "    ordentallas_marca_join = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_in_set\",\n",
    "        kwargs={\n",
    "            \"column\":        \"Talla\",\n",
    "            \"value_set\":      tallas_set,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'marca' no están presentes en el archivo de Orden Tallas\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    result = gx_toolkit.run_expectations_on_df(source, \"ORDENTALLA_MARCAS_JOIN\", [ordentallas_marca_join])\n",
    "    clear_output(wait=True)\n",
    "    if result['status']:\n",
    "        logger.info('Validación exitosa, se promueve a cleansed-zone')\n",
    "    else:\n",
    "        logger.info('WARNING: Validación fallida, continúa.')\n",
    "        logger.info(url)\n",
    "    csv_output_dir = CONTENEDOR_DESTINO + '/' + homologaciones + '/'\n",
    "    datalake.write_csv(source, csv_output_dir+'orden_tallas.csv', sep=\"|\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tarea ean_validar_cantidad_registros sobrescrita. Si quiere cambiar este comportamiento\n",
      "use la variable de ambiente `SOBREESCRIBIR_TAREA` (valor actual = True)\n"
     ]
    }
   ],
   "source": [
    "@task_dq\n",
    "def ean_validar_cantidad_registros(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Valida la canitdad de EANs\"\"\"\n",
    "    csv_input_dir = WD + '/' + homologaciones + '/'\n",
    "    source = datalake.read_csv(csv_input_dir + \"ean.csv\", sep=\"|\")\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando Cantidad EAN...\")\n",
    "    ean_unique = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_unique_value_count_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":        \"EAN\",\n",
    "            \"min_value\":     3000,\n",
    "            \"max_value\":     4000,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"La cantidad de productos presentes excede la esperada\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    result = gx_toolkit.run_expectations_on_df(source, \"CANTIDAD_EAN\", [ean_unique])\n",
    "    clear_output(wait=True)\n",
    "    if result['status']:\n",
    "        logger.info('Validación exitosa, se promueve a cleansed-zone')\n",
    "    else:\n",
    "        logger.info('WARNING: Validación fallida, continúa.')\n",
    "        logger.info(url)\n",
    "    csv_output_dir = CONTENEDOR_DESTINO + '/' + homologaciones + '/'\n",
    "    datalake.write_csv(source, csv_output_dir+'ean.csv', sep=\"|\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tarea atributos_validar_referencias sobrescrita. Si quiere cambiar este comportamiento\n",
      "use la variable de ambiente `SOBREESCRIBIR_TAREA` (valor actual = True)\n"
     ]
    }
   ],
   "source": [
    "@task_dq\n",
    "def atributos_validar_referencias(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Valida la existencia de las referencias para los atributos\"\"\"\n",
    "    csv_input_dir = WD + '/' + homologaciones + '/'\n",
    "    source = datalake.read_csv(csv_input_dir + \"atributos.csv\", sep=\"|\")\n",
    "    validation_set = datalake.read_csv(csv_input_dir + \"ean.csv\", sep=\"|\")\n",
    "    referencia_set = validation_set.REFERENCIA.unique().tolist()\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando Cantidad EAN...\")\n",
    "    ean_unique = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_in_set\",\n",
    "        kwargs={\n",
    "            \"column\":        \"REFERENCIA\",\n",
    "            \"value_set\":      referencia_set,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunas referencias del archivo de Atributos no están definidas en Marcas Propias\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    result = gx_toolkit.run_expectations_on_df(source, \"ATRIBUTOS_REFERENCIAS\", [ean_unique])\n",
    "    clear_output(wait=True)\n",
    "    if result['status']:\n",
    "        logger.info('Validación exitosa, se promueve a cleansed-zone')\n",
    "    else:\n",
    "        logger.info('WARNING: Validación fallida, continúa.')\n",
    "        logger.info(url)\n",
    "    csv_output_dir = CONTENEDOR_DESTINO + '/' + homologaciones + '/'\n",
    "    datalake.write_csv(source, csv_output_dir+'atributos.csv', sep=\"|\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tarea tallasagotadas_validar_join sobrescrita. Si quiere cambiar este comportamiento\n",
      "use la variable de ambiente `SOBREESCRIBIR_TAREA` (valor actual = True)\n"
     ]
    }
   ],
   "source": [
    "@task_dq\n",
    "def tallasagotadas_validar_join(datalake, gx_toolkit, logger):\n",
    "    \"\"\"Veriifca las referencias de las tallas agotadas\"\"\"\n",
    "    csv_input_dir = WD + '/' + homologaciones + '/'\n",
    "    source = datalake.read_csv(csv_input_dir+'tallas_agotadas.csv', sep='|')\n",
    "    validation_set = datalake.read_csv(csv_input_dir+'ean.csv', sep='|')\n",
    "    ean_set = validation_set.EAN.unique().tolist()\n",
    "    logger.info(source.head(1))\n",
    "    logger.info(\"Validando JOIN Orden Tallas...\")\n",
    "\n",
    "    tallasagotadas_marca_join = ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_in_set\",\n",
    "        kwargs={\n",
    "            \"column\":        \"PARTNUMBER\",\n",
    "            \"value_set\":      ean_set,\n",
    "            \"result_format\": \"SUMMARY\"\n",
    "        },\n",
    "        meta={\n",
    "            \"notes\": {\n",
    "                \"format\": \"markdown\",\n",
    "                \"content\": \"Algunos elementos de la columna 'PARTNUMBER' no están presentes en el archivo de EAN\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    result = gx_toolkit.run_expectations_on_df(source, \"test\", [tallasagotadas_marca_join])\n",
    "    clear_output(wait=True)\n",
    "    if result['status']:\n",
    "        logger.info('Validación exitosa, se promueve a cleansed-zone')\n",
    "    else:\n",
    "        logger.info('WARNING: Validación fallida, continúa.')\n",
    "        logger.info(url)\n",
    "    csv_output_dir = CONTENEDOR_DESTINO + '/' + homologaciones + '/'\n",
    "    datalake.write_csv(source, csv_output_dir+'tallas_agotadas.csv', sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulacion de function App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import patch\n",
    "import azure.functions as func\n",
    "from centraal_dataframework.blueprints import framework\n",
    "app = func.FunctionApp()\n",
    "app.register_functions(framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto es solo para obtener la funciones \n",
    "# dentro del notebook\n",
    "funciones = {fun.get_user_function().__name__ : fun.get_user_function() for fun in app.get_functions()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:se programan ['scrapping_validate_column_contents', 'marcaspropias_validate_column_contents', 'homologaciones_validar_cantidad', 'ordentallas_validar_join', 'ean_validar_cantidad_registros', 'atributos_validar_referencias', 'tallasagotadas_validar_join']\n"
     ]
    }
   ],
   "source": [
    "with patch(\"azure.functions.Out\", autospec=True) as mock_msg:\n",
    "    timer = func.timer.TimerRequest(past_due = False)\n",
    "    funciones['check_and_schedule_task'](timer, mock_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TAREA: scrapping_validate_prerequisites--2023-12-05 15:05:15,770-INFO-Validación exitosa, se promueve a cleansed-zone\n",
      "INFO:scrapping_validate_prerequisites:Validación exitosa, se promueve a cleansed-zone\n",
      "TAREA: scrapping_validate_prerequisites--2023-12-05 15:05:15,772-INFO-Se genera un archivo privado: /calidad-datos/validations/scrapping_validate_prerequisites_expectation_suite/__none__/20231205T200442.938201Z/scrapping_validate_prerequisites_source-scrapping_validate_prerequisites_source_SCRAPPING_MANDATORY.html. Visitar portal azure para acceder resultados.\n",
      "INFO:scrapping_validate_prerequisites:Se genera un archivo privado: /calidad-datos/validations/scrapping_validate_prerequisites_expectation_suite/__none__/20231205T200442.938201Z/scrapping_validate_prerequisites_source-scrapping_validate_prerequisites_source_SCRAPPING_MANDATORY.html. Visitar portal azure para acceder resultados.\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://azstuiprduenindustria.blob.core.windows.net/cleansed-zone/raw-zone/scrapping.csv'\n",
      "Request method: 'DELETE'\n",
      "Request headers:\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'Accept': 'application/xml'\n",
      "    'x-ms-date': 'REDACTED'\n",
      "    'x-ms-client-request-id': '9bed4aea-93a9-11ee-a04b-00155d390e13'\n",
      "    'User-Agent': 'azsdk-python-storage-blob/12.18.2 Python/3.8.10 (Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29)'\n",
      "    'Authorization': 'REDACTED'\n",
      "No body was attached to the request\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 404\n",
      "Response headers:\n",
      "    'Content-Length': '215'\n",
      "    'Content-Type': 'application/xml'\n",
      "    'Server': 'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0'\n",
      "    'x-ms-request-id': 'de3d35fe-901e-0055-7cb6-27e00d000000'\n",
      "    'x-ms-client-request-id': '9bed4aea-93a9-11ee-a04b-00155d390e13'\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'x-ms-error-code': 'BlobNotFound'\n",
      "    'Date': 'Tue, 05 Dec 2023 20:05:18 GMT'\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://azstuiprduenindustria.blob.core.windows.net/cleansed-zone/raw-zone/scrapping.csv?comp=REDACTED&blockid=REDACTED'\n",
      "Request method: 'PUT'\n",
      "Request headers:\n",
      "    'Content-Length': '5244575'\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'Content-Type': 'application/octet-stream'\n",
      "    'Accept': 'application/xml'\n",
      "    'x-ms-date': 'REDACTED'\n",
      "    'x-ms-client-request-id': '9c4bd312-93a9-11ee-a04b-00155d390e13'\n",
      "    'User-Agent': 'azsdk-python-storage-blob/12.18.2 Python/3.8.10 (Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29)'\n",
      "    'Authorization': 'REDACTED'\n",
      "A body is sent with the request\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 201\n",
      "Response headers:\n",
      "    'Content-Length': '0'\n",
      "    'Server': 'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0'\n",
      "    'x-ms-request-id': 'de3d36b0-901e-0055-5bb6-27e00d000000'\n",
      "    'x-ms-client-request-id': '9c4bd312-93a9-11ee-a04b-00155d390e13'\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'x-ms-content-crc64': 'REDACTED'\n",
      "    'x-ms-request-server-encrypted': 'REDACTED'\n",
      "    'Date': 'Tue, 05 Dec 2023 20:05:19 GMT'\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://azstuiprduenindustria.blob.core.windows.net/cleansed-zone/raw-zone/scrapping.csv?comp=REDACTED&blockid=REDACTED'\n",
      "Request method: 'PUT'\n",
      "Request headers:\n",
      "    'Content-Length': '5247578'\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'Content-Type': 'application/octet-stream'\n",
      "    'Accept': 'application/xml'\n",
      "    'x-ms-date': 'REDACTED'\n",
      "    'x-ms-client-request-id': '9cfacd90-93a9-11ee-a04b-00155d390e13'\n",
      "    'User-Agent': 'azsdk-python-storage-blob/12.18.2 Python/3.8.10 (Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29)'\n",
      "    'Authorization': 'REDACTED'\n",
      "A body is sent with the request\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 201\n",
      "Response headers:\n",
      "    'Content-Length': '0'\n",
      "    'Server': 'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0'\n",
      "    'x-ms-request-id': 'de3d3ae7-901e-0055-73b6-27e00d000000'\n",
      "    'x-ms-client-request-id': '9cfacd90-93a9-11ee-a04b-00155d390e13'\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'x-ms-content-crc64': 'REDACTED'\n",
      "    'x-ms-request-server-encrypted': 'REDACTED'\n",
      "    'Date': 'Tue, 05 Dec 2023 20:05:19 GMT'\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://azstuiprduenindustria.blob.core.windows.net/cleansed-zone/raw-zone/scrapping.csv?comp=REDACTED&blockid=REDACTED'\n",
      "Request method: 'PUT'\n",
      "Request headers:\n",
      "    'Content-Length': '5244491'\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'Content-Type': 'application/octet-stream'\n",
      "    'Accept': 'application/xml'\n",
      "    'x-ms-date': 'REDACTED'\n",
      "    'x-ms-client-request-id': '9d52d210-93a9-11ee-a04b-00155d390e13'\n",
      "    'User-Agent': 'azsdk-python-storage-blob/12.18.2 Python/3.8.10 (Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29)'\n",
      "    'Authorization': 'REDACTED'\n",
      "A body is sent with the request\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 201\n",
      "Response headers:\n",
      "    'Content-Length': '0'\n",
      "    'Server': 'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0'\n",
      "    'x-ms-request-id': 'de3d3cb9-901e-0055-5db6-27e00d000000'\n",
      "    'x-ms-client-request-id': '9d52d210-93a9-11ee-a04b-00155d390e13'\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'x-ms-content-crc64': 'REDACTED'\n",
      "    'x-ms-request-server-encrypted': 'REDACTED'\n",
      "    'Date': 'Tue, 05 Dec 2023 20:05:20 GMT'\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://azstuiprduenindustria.blob.core.windows.net/cleansed-zone/raw-zone/scrapping.csv?comp=REDACTED&blockid=REDACTED'\n",
      "Request method: 'PUT'\n",
      "Request headers:\n",
      "    'Content-Length': '5247831'\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'Content-Type': 'application/octet-stream'\n",
      "    'Accept': 'application/xml'\n",
      "    'x-ms-date': 'REDACTED'\n",
      "    'x-ms-client-request-id': '9d961db8-93a9-11ee-a04b-00155d390e13'\n",
      "    'User-Agent': 'azsdk-python-storage-blob/12.18.2 Python/3.8.10 (Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29)'\n",
      "    'Authorization': 'REDACTED'\n",
      "A body is sent with the request\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 201\n",
      "Response headers:\n",
      "    'Content-Length': '0'\n",
      "    'Server': 'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0'\n",
      "    'x-ms-request-id': 'de3d3eb4-901e-0055-5bb6-27e00d000000'\n",
      "    'x-ms-client-request-id': '9d961db8-93a9-11ee-a04b-00155d390e13'\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'x-ms-content-crc64': 'REDACTED'\n",
      "    'x-ms-request-server-encrypted': 'REDACTED'\n",
      "    'Date': 'Tue, 05 Dec 2023 20:05:20 GMT'\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://azstuiprduenindustria.blob.core.windows.net/cleansed-zone/raw-zone/scrapping.csv?comp=REDACTED&blockid=REDACTED'\n",
      "Request method: 'PUT'\n",
      "Request headers:\n",
      "    'Content-Length': '1404890'\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'Content-Type': 'application/octet-stream'\n",
      "    'Accept': 'application/xml'\n",
      "    'x-ms-date': 'REDACTED'\n",
      "    'x-ms-client-request-id': '9dd1f1bc-93a9-11ee-a04b-00155d390e13'\n",
      "    'User-Agent': 'azsdk-python-storage-blob/12.18.2 Python/3.8.10 (Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29)'\n",
      "    'Authorization': 'REDACTED'\n",
      "A body is sent with the request\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 201\n",
      "Response headers:\n",
      "    'Content-Length': '0'\n",
      "    'Server': 'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0'\n",
      "    'x-ms-request-id': 'de3d404b-901e-0055-1bb6-27e00d000000'\n",
      "    'x-ms-client-request-id': '9dd1f1bc-93a9-11ee-a04b-00155d390e13'\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'x-ms-content-crc64': 'REDACTED'\n",
      "    'x-ms-request-server-encrypted': 'REDACTED'\n",
      "    'Date': 'Tue, 05 Dec 2023 20:05:21 GMT'\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://azstuiprduenindustria.blob.core.windows.net/cleansed-zone/raw-zone/scrapping.csv?comp=REDACTED'\n",
      "Request method: 'PUT'\n",
      "Request headers:\n",
      "    'Content-Length': '207'\n",
      "    'x-ms-meta-is_directory': 'REDACTED'\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'Content-Type': 'application/xml'\n",
      "    'Accept': 'application/xml'\n",
      "    'x-ms-date': 'REDACTED'\n",
      "    'x-ms-client-request-id': '9dede8ae-93a9-11ee-a04b-00155d390e13'\n",
      "    'User-Agent': 'azsdk-python-storage-blob/12.18.2 Python/3.8.10 (Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.29)'\n",
      "    'Authorization': 'REDACTED'\n",
      "A body is sent with the request\n",
      "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 201\n",
      "Response headers:\n",
      "    'Content-Length': '0'\n",
      "    'Last-Modified': 'Tue, 05 Dec 2023 20:05:21 GMT'\n",
      "    'Etag': '\"0x8DBF5CD82BA1378\"'\n",
      "    'Server': 'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0'\n",
      "    'x-ms-request-id': 'de3d4110-901e-0055-7ab6-27e00d000000'\n",
      "    'x-ms-client-request-id': '9dede8ae-93a9-11ee-a04b-00155d390e13'\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'x-ms-content-crc64': 'REDACTED'\n",
      "    'x-ms-request-server-encrypted': 'REDACTED'\n",
      "    'Date': 'Tue, 05 Dec 2023 20:05:21 GMT'\n"
     ]
    }
   ],
   "source": [
    "# ahora simular la ejecucion\n",
    "funciones['execute_tasks_inqueue'](func.QueueMessage(body = bytes(\"scrapping_validate_prerequisites\",  \"utf-8\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
